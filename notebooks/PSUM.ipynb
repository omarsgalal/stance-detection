{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOodU5lrl9JbqGsa8IwOuBX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"18d024d791294f4eae8252c869b0aee4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec247392b27f4cfab37aa7aeaaec5b4d","IPY_MODEL_9bc05696beb242fdb78a951686a33921","IPY_MODEL_0ec7ad165d45456691cf245a2b9a7c94"],"layout":"IPY_MODEL_db8855c822d24658ad8f7eba0540d8ff"}},"ec247392b27f4cfab37aa7aeaaec5b4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c30b8edc1c1442f9820114c7459fd008","placeholder":"​","style":"IPY_MODEL_fc2eb035853449b29fc31ba665ad504a","value":"Downloading readme: 100%"}},"9bc05696beb242fdb78a951686a33921":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceb1be998d694b4b9580bdfa0dc278d9","max":2381,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ae62f3cc484443c86f8a6372a22e275","value":2381}},"0ec7ad165d45456691cf245a2b9a7c94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bae36037e4c341f3bd72d4cb205c9fa1","placeholder":"​","style":"IPY_MODEL_4b9f9bad7ad2424ea13614ce37484909","value":" 2.38k/2.38k [00:00&lt;00:00, 66.9kB/s]"}},"db8855c822d24658ad8f7eba0540d8ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c30b8edc1c1442f9820114c7459fd008":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc2eb035853449b29fc31ba665ad504a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceb1be998d694b4b9580bdfa0dc278d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ae62f3cc484443c86f8a6372a22e275":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bae36037e4c341f3bd72d4cb205c9fa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9f9bad7ad2424ea13614ce37484909":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c706b648a0ef44ecbcb6406401b0133a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b4ea79b6eb74a5e9da825bddfcaa0cf","IPY_MODEL_0c89f380a31c4edf9f7c2ff63ddcc0e8","IPY_MODEL_2a8366f5e7604972938c2cf8a26bfe17"],"layout":"IPY_MODEL_87a0273dc6d74dcca6e9e1313af87a70"}},"3b4ea79b6eb74a5e9da825bddfcaa0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9129985ec6f4ddf864193b09df7c433","placeholder":"​","style":"IPY_MODEL_438657a818eb42f8a67ccb3b022a6016","value":"Downloading data: 100%"}},"0c89f380a31c4edf9f7c2ff63ddcc0e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_574edbc4e55446939d2b8f35ce5a4b0a","max":1397075,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4fe44d6fdd8499eb0e32b7a7593d037","value":1397075}},"2a8366f5e7604972938c2cf8a26bfe17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_196ded67ca3f46ee8fb5112964f3b294","placeholder":"​","style":"IPY_MODEL_72d17958430d4bf8a64f73e18fd0ae74","value":" 1.40M/1.40M [00:00&lt;00:00, 3.03MB/s]"}},"87a0273dc6d74dcca6e9e1313af87a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9129985ec6f4ddf864193b09df7c433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"438657a818eb42f8a67ccb3b022a6016":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"574edbc4e55446939d2b8f35ce5a4b0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4fe44d6fdd8499eb0e32b7a7593d037":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"196ded67ca3f46ee8fb5112964f3b294":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72d17958430d4bf8a64f73e18fd0ae74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc3587b12ca64345abe5a8cdd16dc6e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_707735d39a9d4d6fbdc25a618da1d8a8","IPY_MODEL_1472ca8fc7a74a00b01b09c4a93dcd26","IPY_MODEL_987a15c0ee664c688bd220007350c7b4"],"layout":"IPY_MODEL_8b38cfa032204540b1c1f703540fb5c4"}},"707735d39a9d4d6fbdc25a618da1d8a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36774724f3e54f52b18beb134a53bdc0","placeholder":"​","style":"IPY_MODEL_7bd0be70c9d441e6904bc16fbdaee07f","value":"Generating train split: 100%"}},"1472ca8fc7a74a00b01b09c4a93dcd26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_415ea4c88fa9408cb90f42ba3dd1c8f6","max":3502,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dbe85e7c63e5438587622502b8599dc9","value":3502}},"987a15c0ee664c688bd220007350c7b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22aab793c6a4755bd4ed89cc8c82be6","placeholder":"​","style":"IPY_MODEL_7a0cd71a8e2548e9a7e4d6cafe3c46e4","value":" 3502/3502 [00:00&lt;00:00, 19783.73 examples/s]"}},"8b38cfa032204540b1c1f703540fb5c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36774724f3e54f52b18beb134a53bdc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd0be70c9d441e6904bc16fbdaee07f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"415ea4c88fa9408cb90f42ba3dd1c8f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbe85e7c63e5438587622502b8599dc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a22aab793c6a4755bd4ed89cc8c82be6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a0cd71a8e2548e9a7e4d6cafe3c46e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Environment Setup"],"metadata":{"id":"LgmyjWbE8g9N"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9okXJEc8a0A","executionInfo":{"status":"ok","timestamp":1714660685510,"user_tz":-180,"elapsed":128948,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"16199e1a-8099-4a6d-b155-503783a71e89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting farasapy\n","  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.66.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2024.2.2)\n","Installing collected packages: farasapy\n","Successfully installed farasapy-0.0.14\n","Collecting arabert\n","  Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyArabic (from arabert)\n","  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: farasapy in /usr/local/lib/python3.10/dist-packages (from arabert) (0.0.14)\n","Collecting emoji==1.4.2 (from arabert)\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy->arabert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy->arabert) (4.66.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from PyArabic->arabert) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (2024.2.2)\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186459 sha256=c76260aba5bdb47a360c057117bb0e126a0037be4b3d6302b8163a99a6267386\n","  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n","Successfully built emoji\n","Installing collected packages: emoji, PyArabic, arabert\n","Successfully installed PyArabic-0.6.15 arabert-1.0.1 emoji-1.4.2\n"]}],"source":["!pip install datasets\n","!pip install -U sentence-transformers\n","!pip install transformers\n","!pip install farasapy\n","!pip install arabert\n","# !pip install openai"]},{"cell_type":"markdown","source":["# Load dataset"],"metadata":{"id":"C6sm-GSJ8qqS"}},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# load dataset\n","dataset = load_dataset(\"NoraAlt/Mawqif_Stance-Detection\")\n","\n","# convert to pandas dataframe\n","df = pd.DataFrame({k: dataset['train'][k] for k, _ in dataset['train'].features.items()})\n","df['stance'] = df['stance'].apply(lambda x: \"Neutral\" if x is None else x)\n","\n","# train test split\n","train_df, test_df = train_test_split(df, test_size=500, random_state=12345)\n","\n","# train val split\n","train_df, val_df = train_test_split(train_df, test_size=300, random_state=12345)\n","\n","# print sizes\n","print(f\"train length: {len(train_df)}\")\n","print(f\"test length: {len(test_df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279,"referenced_widgets":["18d024d791294f4eae8252c869b0aee4","ec247392b27f4cfab37aa7aeaaec5b4d","9bc05696beb242fdb78a951686a33921","0ec7ad165d45456691cf245a2b9a7c94","db8855c822d24658ad8f7eba0540d8ff","c30b8edc1c1442f9820114c7459fd008","fc2eb035853449b29fc31ba665ad504a","ceb1be998d694b4b9580bdfa0dc278d9","0ae62f3cc484443c86f8a6372a22e275","bae36037e4c341f3bd72d4cb205c9fa1","4b9f9bad7ad2424ea13614ce37484909","c706b648a0ef44ecbcb6406401b0133a","3b4ea79b6eb74a5e9da825bddfcaa0cf","0c89f380a31c4edf9f7c2ff63ddcc0e8","2a8366f5e7604972938c2cf8a26bfe17","87a0273dc6d74dcca6e9e1313af87a70","a9129985ec6f4ddf864193b09df7c433","438657a818eb42f8a67ccb3b022a6016","574edbc4e55446939d2b8f35ce5a4b0a","f4fe44d6fdd8499eb0e32b7a7593d037","196ded67ca3f46ee8fb5112964f3b294","72d17958430d4bf8a64f73e18fd0ae74","cc3587b12ca64345abe5a8cdd16dc6e4","707735d39a9d4d6fbdc25a618da1d8a8","1472ca8fc7a74a00b01b09c4a93dcd26","987a15c0ee664c688bd220007350c7b4","8b38cfa032204540b1c1f703540fb5c4","36774724f3e54f52b18beb134a53bdc0","7bd0be70c9d441e6904bc16fbdaee07f","415ea4c88fa9408cb90f42ba3dd1c8f6","dbe85e7c63e5438587622502b8599dc9","a22aab793c6a4755bd4ed89cc8c82be6","7a0cd71a8e2548e9a7e4d6cafe3c46e4"]},"id":"xSLvfdVu8q9W","executionInfo":{"status":"ok","timestamp":1714660693543,"user_tz":-180,"elapsed":8042,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"68f82657-856d-4b0c-fcf1-62649edcc486"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/2.38k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d024d791294f4eae8252c869b0aee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c706b648a0ef44ecbcb6406401b0133a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/3502 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc3587b12ca64345abe5a8cdd16dc6e4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["train length: 2702\n","test length: 500\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import re\n","from transformers import AutoTokenizer\n","from transformers import AutoConfig, AutoModel\n","import transformers\n","from tqdm import tqdm\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from sklearn.model_selection import train_test_split\n","# from arabert.preprocess import ArabertPreprocessor\n","from sklearn.metrics import classification_report\n","from arabert.preprocess import ArabertPreprocessor\n","import gc\n","import re\n","\n","\n","class MawqifDataset(torch.utils.data.Dataset):\n","  def __init__(self, df, tokenizer, model_name, task='stance'):\n","    self.labelsIds = {'Neutral': 0, 'Against': 1, 'Favor': 2}\n","    self.sent_labels = {'Neutral': 0, 'Negative': 1, 'Positive': 2}\n","    self.task = task\n","    if task == 'stance':\n","      self.labels = [self.labelsIds[label] for label in df['stance']]\n","    elif task == 'both':\n","      self.labels = [[self.labelsIds[label] for label in df['stance']], [self.sent_labels[label] for label in df['sentiment']]]\n","    self.targets = df['target'].tolist()\n","    if model_name in [\"aubmindlab/bert-base-arabertv02-twitter\", \"aubmindlab/bert-base-arabertv2\"]:\n","      arabert_prep = ArabertPreprocessor(model_name=model_name)\n","      texts = [arabert_prep.preprocess(t) for t in df['text'].tolist()]\n","    else:\n","      texts = df['text'].tolist()\n","    self.texts = [tokenizer(self.targets[i], text, padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\") for i, text in enumerate(texts)]\n","\n","  def classes(self):\n","    return self.labels\n","\n","  def __len__(self):\n","    return len(self.texts)\n","\n","  def get_batch_labels(self, idx):\n","    if self.task == 'both':\n","        return np.array([self.labels[0][idx], self.labels[1][idx]])\n","    return np.array(self.labels[idx])\n","\n","  def get_batch_texts(self, idx):\n","    return self.texts[idx]\n","\n","  def __getitem__(self, idx):\n","    batch_texts = self.get_batch_texts(idx)\n","    batch_y = self.get_batch_labels(idx)\n","    return batch_texts, batch_y"],"metadata":{"id":"LzACW-DM9D0m","executionInfo":{"status":"ok","timestamp":1714661962050,"user_tz":-180,"elapsed":542,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"M_0rl9tj9K2X"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import re\n","from transformers import AutoTokenizer\n","from transformers import AutoConfig, AutoModel\n","import transformers\n","from tqdm import tqdm\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report"],"metadata":{"id":"NYZmkJUd9Kc-","executionInfo":{"status":"ok","timestamp":1714660698210,"user_tz":-180,"elapsed":6,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class PSUMClassifier(nn.Module):\n","  def __init__(self, model_name= \"UBC-NLP/MARBERT\", n_layers=4, n_classes=3, max_length=128):\n","    super(PSUMClassifier, self).__init__()\n","    self.config = AutoConfig.from_pretrained(model_name)\n","\n","    self.bert = AutoModel.from_pretrained(model_name)\n","\n","    self.bertLayers = nn.ModuleList()\n","    self.linears = nn.ModuleList()\n","    self.n_layers = n_layers\n","\n","    for i in range(n_layers):\n","      self.bertLayers.append(transformers.BertLayer(self.config))\n","      self.linears.append(nn.Linear(768, n_classes))\n","\n","\n","  def forward(self, input_id, mask):\n","    hidden_states = self.bert(input_ids= input_id, attention_mask=mask, return_dict=True, output_hidden_states=True)['hidden_states']\n","    final_outputs = []\n","\n","    for i in range(self.n_layers):\n","      final_outputs.append(self.linears[i](self.bertLayers[i](hidden_states[-i-1])[0][:,0,:]))\n","\n","\n","    return tuple(final_outputs)\n","\n","  def loss(self, output, labels, criterion):\n","    bloss = 0.0\n","    for i in range(self.n_layers):\n","      bloss += criterion(output[i], labels.long())\n","    return bloss\n","\n","  def aggregate(self, output):\n","    agg = output[0]\n","    for i in range(1, len(output)):\n","      agg += output[i]\n","    return agg / len(output)\n","\n","  def calcAcc(self, output, labels):\n","    return (self.aggregate(output).argmax(dim=1) == labels).sum().item()\n","\n","  def evaluate(self, output, test_label, preds, golds):\n","    preds += self.aggregate(output).argmax(dim=1).to(\"cpu\").tolist()\n","    golds += test_label.to(\"cpu\").tolist()\n","    return preds, golds\n","\n","  def evaluation_report(self, preds, golds, is_f1pn=False):\n","    print(classification_report(golds, preds, digits=4))\n","    if is_f1pn:\n","      r = classification_report(golds, preds, digits=4, output_dict=True)\n","      f1pn = (r[\"1\"][\"f1-score\"] + r[\"2\"][\"f1-score\"]) / 2.0\n","      print(f'F1PN: {f1pn:.4f}')"],"metadata":{"id":"zvWa7xdZ9QRd","executionInfo":{"status":"ok","timestamp":1714660698210,"user_tz":-180,"elapsed":5,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class HSUMClassifier(nn.Module):\n","  def __init__(self, model_name= \"UBC-NLP/MARBERT\",n_layers=4, n_classes=3, max_length=128):\n","    super(HSUMClassifier, self).__init__()\n","    self.config = AutoConfig.from_pretrained(model_name)\n","\n","    self.bert = AutoModel.from_pretrained(model_name)\n","\n","    self.bertLayers = nn.ModuleList()\n","    self.linears = nn.ModuleList()\n","    self.n_layers = n_layers\n","\n","    for i in range(n_layers):\n","      self.bertLayers.append(transformers.BertLayer(self.config))\n","      self.linears.append(nn.Linear(768, n_classes))\n","\n","\n","  def forward(self, input_id, mask):\n","    hidden_states = self.bert(input_ids= input_id, attention_mask=mask, return_dict=True, output_hidden_states=True)['hidden_states']\n","    final_outputs = []\n","    berts_outputs = []\n","\n","    berts_outputs.append(self.bertLayers[0](hidden_states[-1]))\n","    final_outputs.append(self.linears[0](berts_outputs[-1][0][:,0,:]))\n","\n","    for i in range(1, self.n_layers):\n","      berts_outputs.append(self.bertLayers[i](hidden_states[-i-1] + berts_outputs[-1][0]))\n","      final_outputs.append(self.linears[i](berts_outputs[-1][0][:,0,:]))\n","\n","\n","    return tuple(final_outputs)\n","\n","  def loss(self, output, labels, criterion):\n","    bloss = 0.0\n","    for i in range(self.n_layers):\n","      bloss += criterion(output[i], labels.long())\n","    return bloss\n","\n","  def aggregate(self, output):\n","    agg = output[0]\n","    for i in range(1, len(output)):\n","      agg += output[i]\n","    return agg / len(output)\n","\n","  def calcAcc(self, output, labels):\n","    return (self.aggregate(output).argmax(dim=1) == labels).sum().item()\n","\n","  def evaluate(self, output, test_label, preds, golds):\n","    preds += self.aggregate(output).argmax(dim=1).to(\"cpu\").tolist()\n","    golds += test_label.to(\"cpu\").tolist()\n","    return preds, golds\n","\n","  def evaluation_report(self, preds, golds, is_f1pn=False):\n","    print(classification_report(golds, preds, digits=4))\n","    if is_f1pn:\n","      r = classification_report(golds, preds, digits=4, output_dict=True)\n","      f1pn = (r[\"1\"][\"f1-score\"] + r[\"2\"][\"f1-score\"]) / 2.0\n","      print(f'F1PN: {f1pn:.4f}')"],"metadata":{"id":"JC5zPkyuHHXF","executionInfo":{"status":"ok","timestamp":1714660698210,"user_tz":-180,"elapsed":5,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class PSUMTwoTasksClassifier(nn.Module):\n","  def __init__(self, model_name= \"UBC-NLP/MARBERT\",n_layers=4, n_classes_1=3, n_classes_2=3, max_length=128, separate_bert_layers_for_tasks=False, informed_by='', one_softmax_informing=False, detach=False):\n","    super(PSUMTwoTasksClassifier, self).__init__()\n","    self.config = AutoConfig.from_pretrained(model_name)\n","\n","    self.bert = AutoModel.from_pretrained(model_name)\n","\n","    self.bertLayers = nn.ModuleList()\n","    if separate_bert_layers_for_tasks:\n","      self.bertLayers2 = nn.ModuleList()\n","    self.linears_1 = nn.ModuleList()\n","    self.linears_2 = nn.ModuleList()\n","    self.n_layers = n_layers\n","    self.n_classes_1 = n_classes_1\n","    self.n_classes_2 = n_classes_2\n","    self.separate_bert_layers_for_tasks = separate_bert_layers_for_tasks\n","    self.all_informed = informed_by != ''\n","    self.informed_by = informed_by\n","    self.one_softmax_informing = one_softmax_informing\n","    self.detach = detach\n","\n","    if self.all_informed:\n","      self.softmaxes_1 = nn.ModuleList()\n","      self.softmaxes_2 = nn.ModuleList()\n","      self.informed_linears_1 = nn.ModuleList()\n","      self.informed_linears_2 = nn.ModuleList()\n","\n","\n","    for i in range(n_layers):\n","      self.bertLayers.append(transformers.BertLayer(self.config))\n","      if separate_bert_layers_for_tasks:\n","        self.bertLayers2.append(transformers.BertLayer(self.config))\n","      self.linears_1.append(nn.Linear(768, n_classes_1))\n","      self.linears_2.append(nn.Linear(768, n_classes_2))\n","\n","      if self.all_informed:\n","        self.softmaxes_1.append(nn.Softmax(dim=1))\n","        self.softmaxes_2.append(nn.Softmax(dim=1))\n","        self.informed_linears_1.append(nn.Linear(768 + n_classes_2, n_classes_1))\n","        self.informed_linears_2.append(nn.Linear(768 + n_classes_1, n_classes_2))\n","\n","\n","  def forward(self, input_id, mask):\n","    hidden_states = self.bert(input_ids= input_id, attention_mask=mask, return_dict=True, output_hidden_states=True)['hidden_states']\n","    final_outputs_1 = []\n","    final_outputs_2 = []\n","\n","    if self.all_informed:\n","      informed_final_outputs_1 = []\n","      informed_final_outputs_2 = []\n","\n","    for i in range(self.n_layers):\n","      final_outputs_1.append(self.linears_1[i](self.bertLayers[i](hidden_states[-i-1])[0][:,0,:]))\n","      if self.separate_bert_layers_for_tasks:\n","        final_outputs_2.append(self.linears_2[i](self.bertLayers2[i](hidden_states[-i-1])[0][:,0,:]))\n","      else:\n","        final_outputs_2.append(self.linears_2[i](self.bertLayers[i](hidden_states[-i-1])[0][:,0,:]))\n","\n","      if self.all_informed and not self.one_softmax_informing:\n","        if self.detach:\n","          fo2i = torch.Tensor.detach(final_outputs_2[i])\n","          fo1i = torch.Tensor.detach(final_outputs_1[i])\n","        else:\n","          fo2i = final_outputs_2[i]\n","          fo1i = final_outputs_1[i]\n","\n","        informed_final_outputs_1.append(self.informed_linears_1[i](torch.cat((self.bertLayers[i](hidden_states[-i-1])[0][:,0,:], self.softmaxes_2[i](fo2i)), dim=1)))\n","        informed_final_outputs_2.append(self.informed_linears_2[i](torch.cat((self.bertLayers[i](hidden_states[-i-1])[0][:,0,:], self.softmaxes_1[i](fo1i)), dim=1)))\n","\n","    if self.all_informed and self.one_softmax_informing:\n","      sum1 = final_outputs_1[0]\n","      sum2 = final_outputs_2[0]\n","      for j in range(1, self.n_layers):\n","        sum1 += final_outputs_1[j]\n","        sum2 += final_outputs_2[j]\n","      sum1 /= self.n_layers\n","      sum2 /= self.n_layers\n","\n","      o1 = self.softmaxes_1[0](sum1)\n","      o2 = self.softmaxes_2[0](sum2)\n","\n","      for i in range(self.n_layers):\n","        informed_final_outputs_1.append(self.informed_linears_1[i](torch.cat((self.bertLayers[i](hidden_states[-i-1])[0][:,0,:], o2), dim=1)))\n","        informed_final_outputs_2.append(self.informed_linears_2[i](torch.cat((self.bertLayers[i](hidden_states[-i-1])[0][:,0,:], o1), dim=1)))\n","\n","    if self.all_informed:\n","      return final_outputs_1, final_outputs_2, informed_final_outputs_1, informed_final_outputs_2\n","\n","    return final_outputs_1, final_outputs_2\n","\n","  def loss(self, output, labels, criterion):\n","    bloss = 0.0\n","    for i in range(self.n_layers):\n","      if self.informed_by in ['', 't1', 'all']:\n","        bloss += criterion(output[0][i], labels[:, 0].long())\n","\n","      if self.informed_by in ['', 't2', 'all']:\n","        bloss += criterion(output[1][i], labels[:, 1].long())\n","\n","      if self.informed_by in ['t2', 'all']:\n","        bloss += criterion(output[2][i], labels[:, 0].long())\n","\n","      if self.informed_by in ['t1', 'all']:\n","        bloss += criterion(output[3][i], labels[:, 1].long())\n","\n","    return bloss\n","\n","  def aggregate(self, output):\n","    if self.informed_by == '':\n","      t1_idx = 0\n","      t2_idx = 1\n","    elif self.informed_by == 't1':\n","      t1_idx = 0\n","      t2_idx = 3\n","    elif self.informed_by == 't2':\n","      t1_idx = 2\n","      t2_idx = 1\n","    elif self.informed_by == 'all':\n","      t1_idx = 2\n","      t2_idx = 3\n","\n","    agg1 = output[t1_idx][0]\n","    agg2 = output[t2_idx][0]\n","    for i in range(1, len(output[0])):\n","      agg1 += output[t1_idx][i]\n","      agg2 += output[t2_idx][i]\n","    return agg1 / len(output[t1_idx]), agg2 / len(output[t2_idx])\n","\n","  def calcAcc(self, output, labels):\n","    return (self.aggregate(output)[0].argmax(dim=1) == labels[:, 0]).sum().item()\n","\n","  def evaluate(self, output, test_label, preds, golds):\n","    if len(preds) == 0:\n","      preds = [[], []]\n","      golds = [[], []]\n","\n","    agg1, agg2 = self.aggregate(output)\n","    preds[0] += agg1.argmax(dim=1).to(\"cpu\").tolist()\n","    golds[0] += test_label[:, 0].to(\"cpu\").tolist()\n","    preds[1] += agg2.argmax(dim=1).to(\"cpu\").tolist()\n","    golds[1] += test_label[:, 1].to(\"cpu\").tolist()\n","\n","    return preds, golds\n","\n","  def evaluation_report(self, preds, golds, is_f1pn=False):\n","    print(\"########## Task 1 Results ###############\")\n","    print(classification_report(golds[0], preds[0], digits=4))\n","    if self.n_classes_1 == 3:\n","      r = classification_report(golds[0], preds[0], digits=4, output_dict=True)\n","      f1pn = (r[\"1\"][\"f1-score\"] + r[\"2\"][\"f1-score\"]) / 2.0\n","      print(f'F1PN: {f1pn:.4f}')\n","\n","    print(\"\\n\\n########## Task 2 Results ###############\")\n","    print(classification_report(golds[1], preds[1], digits=4))\n","    if self.n_classes_2 == 3:\n","      r = classification_report(golds[1], preds[1], digits=4, output_dict=True)\n","      f1pn = (r[\"1\"][\"f1-score\"] + r[\"2\"][\"f1-score\"]) / 2.0\n","      print(f'F1PN: {f1pn:.4f}')"],"metadata":{"id":"ZTRTnhW3xhs8","executionInfo":{"status":"ok","timestamp":1714661756575,"user_tz":-180,"elapsed":2,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"IRnFMh7vAI67"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import re\n","from transformers import AutoTokenizer\n","from transformers import AutoConfig, AutoModel\n","import transformers\n","from tqdm import tqdm\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from sklearn.model_selection import train_test_split\n","from arabert.preprocess import ArabertPreprocessor\n","from sklearn.metrics import classification_report\n","\n","\n","def train(model, train_data, val_data, learning_rate, epochs, batch_size, model_path_save, task, informed_by):\n","  \"\"\"\n","  model: the custom model class\n","  train_data: from the custom dataset class\n","  val_data: from the custom dataset class\n","  \"\"\"\n","\n","  train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","  val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n","\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = Adam(model.parameters(), lr= learning_rate)\n","\n","  if use_cuda:\n","    model = model.cuda()\n","    criterion = criterion.cuda()\n","  val_loss_min = float(\"inf\")\n","  my_metric = 0.0\n","  for epoch_num in range(epochs):\n","    total_acc_train = 0\n","    total_loss_train = 0\n","\n","    for train_input, train_label in tqdm(train_dataloader):\n","      train_label = train_label.to(device)\n","      mask = train_input['attention_mask'].to(device)\n","      input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","      output = model(input_id, mask)\n","\n","      batch_loss = model.loss(output, train_label, criterion)\n","      total_loss_train += batch_loss.item()\n","\n","      acc = model.calcAcc(output, train_label)\n","      total_acc_train += acc\n","\n","      model.zero_grad()\n","      batch_loss.backward()\n","      optimizer.step()\n","      os.system('cls')\n","\n","\n","    total_acc_val = 0\n","    total_loss_val = 0\n","    preds = []\n","    golds = []\n","\n","    with torch.no_grad():\n","      for val_input, val_label in val_dataloader:\n","\n","        val_label = val_label.to(device)\n","        mask = val_input['attention_mask'].to(device)\n","        input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","        output = model(input_id, mask)\n","\n","        batch_loss = model.loss(output, val_label, criterion)\n","        total_loss_val += batch_loss.item()\n","\n","        acc = model.calcAcc(output, val_label)\n","        total_acc_val += acc\n","\n","        preds, golds = model.evaluate(output, val_label, preds, golds)\n","\n","\n","    if task == 'sentiment' or task == 'stance' or informed_by == 't2':\n","      if informed_by == 't2':\n","        golds, preds = golds[0], preds[0]\n","      r = classification_report(golds, preds, output_dict=True)\n","      f1_pn = (r[\"1\"][\"f1-score\"] + r[\"2\"][\"f1-score\"]) / 2.0\n","      printed_metric = f1_pn\n","      if f1_pn >= my_metric:\n","        my_metric = f1_pn\n","        torch.save(model, model_path_save)\n","      # if total_loss_val <= val_loss_min:\n","      #   val_loss_min = total_loss_val\n","      #   torch.save(model, model_path_save)\n","    elif task == 'sarcasm' or informed_by == 't1':\n","      if informed_by == 't1':\n","        golds, preds = golds[1], preds[1]\n","      r = classification_report(golds, preds, output_dict=True)\n","      printed_metric = r[\"1\"][\"f1-score\"]\n","      if r[\"1\"][\"f1-score\"] >= my_metric:\n","        my_metric = r[\"1\"][\"f1-score\"]\n","        torch.save(model, model_path_save)\n","    elif task == \"both\" or task == 'all':\n","      r = classification_report(golds[0], preds[0], output_dict=True)\n","      f1_pn = (r[\"1\"][\"f1-score\"] + r[\"2\"][\"f1-score\"]) / 2.0\n","      printed_metric = f1_pn\n","      if f1_pn >= my_metric:\n","        my_metric = f1_pn\n","        torch.save(model, model_path_save)\n","\n","\n","    print(\n","        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data)} \\\n","        | Train Accuracy: {total_acc_train / len(train_data)} \\\n","        | Val Loss: {total_loss_val / len(val_data)} \\\n","        | Val Accuracy: {total_acc_val / len(val_data)}')\n","\n","    print(f\"########### Target Metric: {printed_metric} ##############\")"],"metadata":{"id":"P40Ynr4SAJ0t","executionInfo":{"status":"ok","timestamp":1714662090384,"user_tz":-180,"elapsed":468,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["# Validate"],"metadata":{"id":"Vdu5Qb1kBws2"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import re\n","from transformers import AutoTokenizer\n","from transformers import AutoConfig, AutoModel\n","import transformers\n","from tqdm import tqdm\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from sklearn.model_selection import train_test_split\n","from arabert.preprocess import ArabertPreprocessor\n","from sklearn.metrics import classification_report\n","\n","\n","\n","\n","def evaluate(model, test_data, batch_size=16, task='sentiment', show_eval=True):\n","\n","  test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n","\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  if use_cuda:\n","    model = model.cuda()\n","\n","  preds = []\n","  golds = []\n","  with torch.no_grad():\n","\n","    for test_input, test_label in tqdm(test_dataloader):\n","      test_label = test_label.to(device)\n","      mask = test_input['attention_mask'].to(device)\n","      input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","      output = model(input_id, mask)\n","      preds, golds = model.evaluate(output, test_label, preds, golds)\n","\n","      os.system('cls')\n","\n","  print()\n","  if show_eval:\n","    model.evaluation_report(preds, golds, task == 'sentiment' or task == 'stance' or task == 'both' or task == \"all\")\n","  return preds"],"metadata":{"id":"aUS7WF5hByJr","executionInfo":{"status":"ok","timestamp":1714665183564,"user_tz":-180,"elapsed":320,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":["# Running"],"metadata":{"id":"iQt9XYMtCHgd"}},{"cell_type":"code","source":["task = 'both' # 'sentiment', 'sarcasm', 'both', 'all'\n","freeze = True\n","EPOCHS = 5\n","LR = 5e-4\n","batch_size = 32\n","model_path_save = \"model.pth\"\n","informed_by = '' # '', 't1', 't2', 'all'\n","n_classes = 3"],"metadata":{"id":"OwAtfetcCM3_","executionInfo":{"status":"ok","timestamp":1714661784993,"user_tz":-180,"elapsed":339,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model_name = \"UBC-NLP/MARBERT\"\n","# model_name = \"aubmindlab/bert-base-arabertv02-twitter\""],"metadata":{"id":"CJIJmirsCu_n","executionInfo":{"status":"ok","timestamp":1714663246225,"user_tz":-180,"elapsed":320,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# model = PSUMClassifier(model_name,n_layers=4, n_classes=n_classes)\n","# model = HSUMClassifier(model_name,n_layers=4, n_classes=n_classes)\n","model = PSUMTwoTasksClassifier(model_name,n_layers=4, n_classes_1=3, n_classes_2=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-Zv1Qe2DEXU","executionInfo":{"status":"ok","timestamp":1714663249559,"user_tz":-180,"elapsed":3030,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"4c9e5a23-5d78-4764-d115-6bdc0ca6e5f9"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["if freeze:\n","  for param in model.bert.parameters():\n","    param.requires_grad = False"],"metadata":{"id":"StoMxGvvDHrJ","executionInfo":{"status":"ok","timestamp":1714663252294,"user_tz":-180,"elapsed":366,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name)\n","trainDataset, valDataset = MawqifDataset(train_df, tokenizer, model_name, task=task), MawqifDataset(val_df, tokenizer, model_name, task=task)"],"metadata":{"id":"fUmBTG_1DI3E","executionInfo":{"status":"ok","timestamp":1714663253961,"user_tz":-180,"elapsed":1369,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["train(model, trainDataset, valDataset, LR, EPOCHS, batch_size, model_path_save, task, informed_by)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5TRmyBbDhqB","executionInfo":{"status":"ok","timestamp":1714662817222,"user_tz":-180,"elapsed":268378,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"1692824c-ad46-43f5-ff6b-def2b1283a40"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:48<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss: 0.19455283928764563         | Train Accuracy: 0.7379718726868986         | Val Loss: 0.15324620405832926         | Val Accuracy: 0.8133333333333334\n","########### Target Metric: 0.8313492063492063 ##############\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:47<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss: 0.15026840922746015         | Train Accuracy: 0.7994078460399704         | Val Loss: 0.16226173957188925         | Val Accuracy: 0.79\n","########### Target Metric: 0.8170002007897731 ##############\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:47<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss: 0.129348949447197         | Train Accuracy: 0.8478904515173945         | Val Loss: 0.16632586399714153         | Val Accuracy: 0.8133333333333334\n","########### Target Metric: 0.8412667919919865 ##############\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:48<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss: 0.09725766385775156         | Train Accuracy: 0.9111769059955589         | Val Loss: 0.18954864343007405         | Val Accuracy: 0.8233333333333334\n","########### Target Metric: 0.8528825995807128 ##############\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:48<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss: 0.07236556045926121         | Train Accuracy: 0.957438934122872         | Val Loss: 0.1990172306696574         | Val Accuracy: 0.8266666666666667\n","########### Target Metric: 0.8431054199432452 ##############\n"]}]},{"cell_type":"code","source":["testDataset = MawqifDataset(test_df, tokenizer, model_name, task=task)\n","loaded_model = torch.load(model_path_save)\n","loaded_model.eval()\n","model.eval()\n","evaluate(loaded_model, testDataset, batch_size, task)\n","print()\n","evaluate(model, testDataset, batch_size, task)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXT4Z_uhDrLE","executionInfo":{"status":"ok","timestamp":1714662828959,"user_tz":-180,"elapsed":11768,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"2f449e39-a1c6-440f-8971-577bad3de68f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:05<00:00,  2.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","########## Task 1 Results ###############\n","              precision    recall  f1-score   support\n","\n","           0     0.7647    0.2407    0.3662        54\n","           1     0.6011    0.8462    0.7029       130\n","           2     0.8767    0.8323    0.8539       316\n","\n","    accuracy                         0.7720       500\n","   macro avg     0.7475    0.6397    0.6410       500\n","weighted avg     0.7929    0.7720    0.7620       500\n","\n","F1PN: 0.7784\n","\n","\n","########## Task 2 Results ###############\n","              precision    recall  f1-score   support\n","\n","           0     0.6972    0.4294    0.5315       177\n","           1     0.5333    0.7080    0.6084       113\n","           2     0.7303    0.8381    0.7805       210\n","\n","    accuracy                         0.6640       500\n","   macro avg     0.6536    0.6585    0.6401       500\n","weighted avg     0.6741    0.6640    0.6534       500\n","\n","F1PN: 0.6944\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:05<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","########## Task 1 Results ###############\n","              precision    recall  f1-score   support\n","\n","           0     0.5366    0.4074    0.4632        54\n","           1     0.6531    0.7385    0.6931       130\n","           2     0.8622    0.8513    0.8567       316\n","\n","    accuracy                         0.7740       500\n","   macro avg     0.6839    0.6657    0.6710       500\n","weighted avg     0.7726    0.7740    0.7717       500\n","\n","F1PN: 0.7749\n","\n","\n","########## Task 2 Results ###############\n","              precision    recall  f1-score   support\n","\n","           0     0.6358    0.5819    0.6077       177\n","           1     0.6147    0.5929    0.6036       113\n","           2     0.7598    0.8286    0.7927       210\n","\n","    accuracy                         0.6880       500\n","   macro avg     0.6701    0.6678    0.6680       500\n","weighted avg     0.6831    0.6880    0.6845       500\n","\n","F1PN: 0.6982\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7POaibSYFq92","executionInfo":{"status":"ok","timestamp":1714661011427,"user_tz":-180,"elapsed":26675,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"8b713281-2c42-40a8-ffb0-c96a7638c8b4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp \"model.pth\" \"/content/drive/MyDrive/PhD/CU/Courses/NLP/Project_data/pth_models/arabertTwitter_PSUM_MTL_LR_5e-4_0.7784.pth\""],"metadata":{"id":"Pv7HI-j7FsTd","executionInfo":{"status":"ok","timestamp":1714662879820,"user_tz":-180,"elapsed":2934,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["torch.save(model, model_path_save)"],"metadata":{"id":"HGd4dRBPIU0v","executionInfo":{"status":"ok","timestamp":1714662429001,"user_tz":-180,"elapsed":6698,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["# Load saved Model and Eval\n","\n"],"metadata":{"id":"dOlfRcNP42OR"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score, classification_report\n","def evaluate_official(test_df, y_pred):\n","    sum_f2_final = 0\n","    sum_f3_final = 0\n","    results = {}\n","    for target in test_df[\"target\"].unique():\n","        target_indices = [i for i in range(len(test_df['target'].tolist())) if test_df['target'].tolist()[i] == target]\n","        filtered_test_labels = [test_df['stance_int'].tolist()[i] for i in target_indices]\n","        filtered_predictions = [y_pred[i] for i in target_indices]\n","        # print(classification_report(filtered_test_labels, filtered_predictions))\n","        f1_3class = f1_score(filtered_test_labels, filtered_predictions, average = None)\n","        sum_f2_final += (f1_3class[1] + f1_3class[2])/2\n","        sum_f3_final += sum(f1_3class)/3\n","        results[target] = {\"F1_score_2class\": (f1_3class[0] + f1_3class[1])/2, \"F1_score_3class\": sum(f1_3class)/3}\n","    results[\"All Targets\"] = {\"F1_score_2class\": sum_f2_final/3, \"F1_score_3class\": sum_f3_final/3}\n","    return results"],"metadata":{"id":"nQenU2MB-6d3","executionInfo":{"status":"ok","timestamp":1714665159372,"user_tz":-180,"elapsed":329,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["paths = [\n","    \"/content/drive/MyDrive/PhD/CU/Courses/NLP/Project_data/pth_models/MARBERT_PSUM_MTL_LR_5e-4_0.7918.pth\",\n","    \"/content/drive/MyDrive/PhD/CU/Courses/NLP/Project_data/pth_models/arabertTwitter_PSUM_MTL_LR_5e-4_0.7784.pth\",\n","    \"/content/drive/MyDrive/PhD/CU/Courses/NLP/Project_data/pth_models/MARBERT_PSUM_LR_5e-4_0.7724.pth\",\n","    \"/content/drive/MyDrive/PhD/CU/Courses/NLP/Project_data/pth_models/arabertTwitter_PSUM_LR_5e-4_0.7793.pth\"\n","]\n","\n","tasks = [\n","    \"both\",\n","    \"both\",\n","    \"stance\",\n","    \"stance\"\n","]\n","\n","model_names = [\n","    \"UBC-NLP/MARBERT\",\n","    \"aubmindlab/bert-base-arabertv02-twitter\",\n","    \"UBC-NLP/MARBERT\",\n","    \"aubmindlab/bert-base-arabertv02-twitter\"\n","]\n","\n","stance_to_int = {\n","  \"Against\": 1,\n","  \"Favor\": 2,\n","  \"Neutral\": 0\n","}\n","int_to_stance = {value: key for key, value in stance_to_int.items()}\n","\n","test_df['stance_int'] = test_df['stance'].map(stance_to_int)\n","\n","for i in range(len(paths)):\n","  if i < 2:\n","    model = PSUMTwoTasksClassifier(model_names[i],n_layers=4, n_classes_1=3, n_classes_2=3)\n","  else:\n","    model = PSUMClassifier(model_names[i],n_layers=4, n_classes=3)\n","  model = torch.load(paths[i])\n","  tokenizer = AutoTokenizer.from_pretrained(model_names[i])\n","  testDataset = MawqifDataset(test_df, tokenizer, model_names[i], task=tasks[i])\n","  preds = evaluate(model, testDataset, batch_size, task, False)\n","  if i < 2:\n","    preds = preds[0]\n","  print(evaluate_official(test_df, preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Ata3mfAJWe2","executionInfo":{"status":"ok","timestamp":1714665413483,"user_tz":-180,"elapsed":60596,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"0d6cca95-5711-4cde-bb4b-bcb32d1dbb63"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","100%|██████████| 16/16 [00:05<00:00,  2.93it/s]\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","{'Covid Vaccine': {'F1_score_2class': 0.625, 'F1_score_3class': 0.6718106995884773}, 'Digital Transformation': {'F1_score_2class': 0.5060606060606061, 'F1_score_3class': 0.6408384924513957}, 'Women empowerment': {'F1_score_2class': 0.44457013574660637, 'F1_score_3class': 0.5869783810960282}, 'All Targets': {'F1_score_2class': 0.7630616498158137, 'F1_score_3class': 0.6332091910453004}}\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 16/16 [00:05<00:00,  2.82it/s]\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","{'Covid Vaccine': {'F1_score_2class': 0.5433047590895654, 'F1_score_3class': 0.5993396380507617}, 'Digital Transformation': {'F1_score_2class': 0.4817813765182186, 'F1_score_3class': 0.6281420207963184}, 'Women empowerment': {'F1_score_2class': 0.43766233766233764, 'F1_score_3class': 0.5774891774891775}, 'All Targets': {'F1_score_2class': 0.7462259913204666, 'F1_score_3class': 0.6016569454454191}}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:04<00:00,  3.54it/s]\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","{'Covid Vaccine': {'F1_score_2class': 0.6487274655355248, 'F1_score_3class': 0.6745231935841929}, 'Digital Transformation': {'F1_score_2class': 0.41050903119868637, 'F1_score_3class': 0.5787157378962952}, 'Women empowerment': {'F1_score_2class': 0.42840909090909096, 'F1_score_3class': 0.5702907452907454}, 'All Targets': {'F1_score_2class': 0.7345596494058272, 'F1_score_3class': 0.6078432255904112}}\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 16/16 [00:04<00:00,  3.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","{'Covid Vaccine': {'F1_score_2class': 0.6757478632478633, 'F1_score_3class': 0.7121473210182888}, 'Digital Transformation': {'F1_score_2class': 0.34224598930481287, 'F1_score_3class': 0.5381873028931853}, 'Women empowerment': {'F1_score_2class': 0.5022321428571429, 'F1_score_3class': 0.6243837181337182}, 'All Targets': {'F1_score_2class': 0.7185485698590538, 'F1_score_3class': 0.6249061140150641}}\n"]}]},{"cell_type":"code","source":["|"],"metadata":{"id":"NaREoM306k8i","executionInfo":{"status":"ok","timestamp":1714664293880,"user_tz":-180,"elapsed":412,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V1p0HavM80-3","executionInfo":{"status":"ok","timestamp":1714664442472,"user_tz":-180,"elapsed":3,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mrECFTK85vA","executionInfo":{"status":"ok","timestamp":1714664442770,"user_tz":-180,"elapsed":3,"user":{"displayName":"Omar Samir Galal Mohamed","userId":"16601359149676800360"}},"outputId":"7a4c04fd-eb03-48ed-ba37-5bf99361a838"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Covid Vaccine': {'F1_score_2class': 0.625, 'F1_score_3class': 0.6718106995884773}, 'Digital Transformation': {'F1_score_2class': 0.5060606060606061, 'F1_score_3class': 0.6408384924513957}, 'Women empowerment': {'F1_score_2class': 0.44457013574660637, 'F1_score_3class': 0.5869783810960282}, 'All Targets': {'F1_score_2class': 0.7630616498158137, 'F1_score_3class': 0.6332091910453004}}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"k9jBf-Dh9BVY"},"execution_count":null,"outputs":[]}]}